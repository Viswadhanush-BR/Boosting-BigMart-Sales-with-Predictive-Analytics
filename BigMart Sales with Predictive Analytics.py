# -*- coding: utf-8 -*-
"""Micro Analysis, Macro Outcomes: Boosting BigMart Sales with Predictive Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ET461ELMtC1wdcdXOvzV6eNIZVzXqgVM

# **Micro Analysis, Macro Outcomes: Boosting BigMart Sales with Predictive Analytics**

by

**VISWADHANUSH B R**

**GURUPRASATH B**

**ASHFAQ SULTAN M**

**Importing Libraries**
"""

#Essential Libraries
import pandas as pd
import numpy as np

#Data Visualization Libraries
import seaborn as sns
import matplotlib.pyplot as plt
from bokeh.io import output_notebook, show
from bokeh.plotting import figure
from plotly import graph_objs as go
import plotly.express as px

#Machine Learning Libraries
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.metrics import mean_squared_error, r2_score

# For Bokeh in Colab
output_notebook()

#Warnings
import warnings
warnings.filterwarnings('ignore')

"""The code imports several libraries for data analysis and visualization. **Pandas** and **NumPy** are used for data manipulation and numerical computations. **Seaborn** and **Matplotlib** provide tools for static visualizations, while **Bokeh** and **Plotly** enable interactive plots. For machine learning, **Scikit-learn** offers algorithms like Decision Trees and Random Forests, while **XGBoost** is used for boosting models. The libraries collectively facilitate efficient data handling, comprehensive visual analysis, and robust predictive modeling for informed decision-making.

**Loading Dataset**
"""

train = pd.read_csv('/content/Train.csv')
test = pd.read_csv('/content/Test.csv')

"""The datasets were successfully loaded using pandas with the `read_csv` function. The training data is stored in the variable `train`, while the test data is in `test`. This setup allows for subsequent analysis and model training on the training set, followed by evaluation on the test set.

**Data Preprocessing**
"""

#Checking Null Values for Train Dataset
train.isnull().sum()

#Checking Null Values for Test Dataset
test.isnull().sum()

data = pd.concat([train_data, test_data], ignore_index=True)
data['Item_Weight'].fillna(data['Item_Weight'].mean(), inplace=True)

if 'Outlet_Size' in data.columns:
    data['Outlet_Size'].fillna(data['Outlet_Size'].mode()[0], inplace=True)

#Performing one-hot encoding after handling missing values
data = pd.get_dummies(data, drop_first=True)

train_data = data[:len(train_data)]
test_data = data[len(train_data):]

X = train_data.drop(columns=['Item_Outlet_Sales'])
y = train_data['Item_Outlet_Sales']
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

"""The code performs essential data preprocessing steps on the training and test datasets. It checks for null values, finding and addressing them by filling missing entries in the `Item_Weight` column with the mean and in the `Outlet_Size` column with the mode. Next, one-hot encoding is applied to convert categorical variables into a numerical format, enhancing model compatibility. The processed data is split back into training and test sets, with the features stored in `X` and the target variable `y`. Finally, the training data is divided into training and validation sets using an 80-20 split for model evaluation.

**Exploratory Data Analysis**
"""

#Sales Distribution Plot
hist, edges = np.histogram(train_data['Item_Outlet_Sales'], bins=50)
p = figure(title="Distribution of Item Outlet Sales", background_fill_color="#fafafa")
p.quad(top=hist, bottom=0, left=edges[:-1], right=edges[1:], fill_color="darkblue", line_color="black", alpha=0.7)
show(p)

"""This histogram shows the distribution of item outlet sales with a right-skewed distribution, meaning most sales are on the lower end, and fewer items have high sales values. The peak on the left side represents the majority of items sold in lower quantities, while the long tail to the right indicates a smaller number of items with significantly higher sales."""

#Sales by Outlet Type
fig = px.box(train_data, x='Outlet_Type_Supermarket Type1', y='Item_Outlet_Sales',
             title="Sales by Outlet Type", labels={'x':'Outlet Type', 'y':'Item Outlet Sales'})
fig.show()

"""This box plot shows the distribution of item outlet sales based on whether the outlet type is **"Supermarket Type1"** (true) or not (false). Both categories have a similar median sales level, but **"Supermarket Type1"** outlets exhibit a slightly wider range of sales values, indicating more variability. Additionally, both types have several high outliers, with sales reaching up to 12,000, although the majority of sales are concentrated below 5,000.

**Predictive Modeling**
"""

# Dictionary to store performance metrics for comparison
performance_metrics = {'Model': [], 'RMSE': [], 'R2 Score': []}

#Evaluating model performance
def evaluate_model(model, X_val, y_val, model_name):
    y_pred = model.predict(X_val)
    rmse = np.sqrt(mean_squared_error(y_val, y_pred))
    r2 = r2_score(y_val, y_pred)
    print(f"{model_name} - RMSE: {rmse:.2f}, R2 Score: {r2:.2f}")
    performance_metrics['Model'].append(model_name)
    performance_metrics['RMSE'].append(rmse)
    performance_metrics['R2 Score'].append(r2)
    return rmse, r2

"""The function **evaluate_model** assesses model performance by predicting validation data and calculating RMSE and RÂ² scores. It stores these metrics in a dictionary for further analysis, aiding model comparison."""

#Generating Actual vs. Predicted plot
def plot_actual_vs_predicted(y_val, y_pred, model_name):
    fig = go.Figure()
    fig.add_trace(go.Scatter(x=y_val, y=y_pred, mode='markers',
                             name="Predictions vs Actuals", marker=dict(color="blue", opacity=0.6)))
    fig.add_trace(go.Scatter(x=[y_val.min(), y_val.max()], y=[y_val.min(), y_val.max()],
                             mode='lines', name="Perfect Fit", line=dict(color="red")))
    fig.update_layout(title=f"{model_name} - Predictions vs Actuals",
                      xaxis_title="Actual Item Outlet Sales",
                      yaxis_title="Predicted Item Outlet Sales",
                      showlegend=True)
    fig.show()

"""The **plot_actual_vs_predicted** function creates a scatter plot comparing actual versus predicted values for a given model. It uses blue markers to represent predictions and includes a red line indicating a perfect fit. The plot effectively visualizes model accuracy, helping identify discrepancies between predicted and actual sales."""

#Decision Tree Regression
print("Decision Tree:")
dt_model = DecisionTreeRegressor(random_state=42)
dt_model.fit(X_train, y_train)
evaluate_model(dt_model, X_val, y_val, "Decision Tree")

# Decision Tree - Predictions vs Actuals
y_pred_dt = dt_model.predict(X_val)
plot_actual_vs_predicted(y_val, y_pred_dt, "Decision Tree")

"""This scatter plot compares the actual versus predicted item outlet sales from a decision tree model. The red line represents a perfect fit, where predictions equal actual values. Most points are close to the line for lower sales, indicating reasonable accuracy in that range. However, as sales increase, predictions become more scattered, suggesting that the model struggles with high sales values, likely due to overfitting or limitations in handling extreme values."""

#Random Forest Regression
print("\nRandom Forest:")
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
evaluate_model(rf_model, X_val, y_val, "Random Forest")

# Random Forest - Predictions vs Actuals
y_pred_rf = rf_model.predict(X_val)
plot_actual_vs_predicted(y_val, y_pred_rf, "Random Forest")

"""The scatter plot shows the Random Forest model's predictions against actual values for item outlet sales. The majority of points are closely aligned along the red "Perfect Fit" line, indicating good model performance. However, there is a spread at higher sales values, suggesting that the model may underpredict for higher sales. This dispersion highlights potential model limitations at extreme values, though it performs reasonably well overall in predicting sales within the observed range."""

#XGBoost
print("\nXGBoost:")
xgb_model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)
xgb_model.fit(X_train, y_train)
evaluate_model(xgb_model, X_val, y_val, "XGBoost")

# XGBoost - Predictions vs Actuals
y_pred_xgb = xgb_model.predict(X_val)
plot_actual_vs_predicted(y_val, y_pred_xgb, "XGBoost")

"""The scatter plot compares XGBoost model predictions to actual item outlet sales values. Most points lie close to the red "Perfect Fit" line, showing that the model predicts well for many observations. However, it tends to underpredict higher sales, similar to the Random Forest model, as seen by the spread of points above the line at larger values. This suggests that while XGBoost captures general trends, it struggles with high-value predictions, indicating potential areas for model improvement.

**Model Comparison and Visualization**
"""

performance_df = pd.DataFrame(performance_metrics)

# Plotting RMSE and R2 Score comparison
plt.figure(figsize=(14, 6))

# RMSE comparison
plt.subplot(1, 2, 1)
sns.barplot(x='Model', y='RMSE', data=performance_df, palette='viridis')
plt.title("Model Comparison - RMSE")
plt.xlabel("Model")
plt.ylabel("Root Mean Squared Error (RMSE)")

# R2 Score comparison
plt.subplot(1, 2, 2)
sns.barplot(x='Model', y='R2 Score', data=performance_df, palette='viridis')
plt.title("Model Comparison - R2 Score")
plt.xlabel("Model")
plt.ylabel("R2 Score")

plt.tight_layout()
plt.show()

"""**Conclusion**"""

best_model = performance_df.loc[performance_df['RMSE'].idxmin()]
print("\nConclusion:")
print("Performance summary:")
print(performance_df)
print(f"\nBest model based on RMSE: {best_model['Model']} with RMSE: {best_model['RMSE']:.2f} and R2 Score: {best_model['R2 Score']:.2f}")

"""In our analysis of BigMart sales, we evaluated three predictive models: Decision Tree Regression, Random Forest Regression, and XGBoost. The performance summary indicated that **XGBoost** emerged as the best model, achieving the lowest **RMSE of 1050.92** and the highest **RÂ² score of 0.59**. This suggests that XGBoost effectively captures the variability in sales data compared to the other models. Utilizing this model can enhance decision-making and strategic planning, ultimately boosting BigMart's sales performance through informed insights."""